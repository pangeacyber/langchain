{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangea AI Security Tools\n",
    "\n",
    "Pangea's tools for LangChain provide AI security features to protect your applications and data. Using these tools you can:\n",
    "\n",
    "- Defend against prompt injection attacks.\n",
    "- Prevent the exposure of sensitive information, including:\n",
    "  - Personally Identifiable Information (PII)\n",
    "  - Protected Health Information (PHI)\n",
    "  - Financial data\n",
    "  - Secrets\n",
    "  - Intellectual property\n",
    "  - Profanity\n",
    "- Remove malicious content from inputs and outputs, such as IP addresses, domains, and URLs.\n",
    "- Monitor user inputs and model responses to support threat analysis, auditing, and compliance efforts.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### OpenAI API key\n",
    "\n",
    "The examples below use OpenAI models. To run them, get your [OpenAI API key](https://platform.openai.com/api-keys) and export it as an environment variable:\n",
    "\n",
    "- `OPENAI_API_KEY`\n",
    "\n",
    "### Pangea project\n",
    "\n",
    "Sign up for a free [Pangea account](https://pangea.cloud/signup) to access the security services required for these tools.\n",
    "\n",
    "After signing up, click **Skip** on the **Get started with a common service** screen. This will take you to the Pangea User Console, where you can enable the specific services needed.\n",
    "\n",
    "For details about Pangea services and their features, visit the Pangea website:\n",
    "- [AI Guard](https://pangea.cloud/services/ai-guard/)\n",
    "- [Redact](https://pangea.cloud/services/redact/)\n",
    "- [Domain Intel](https://pangea.cloud/services/domain-intel/reputation/)\n",
    "- [IP Intel](https://pangea.cloud/services/ip-intel/reputation/)\n",
    "- [URL Intel](https://pangea.cloud/services/url-intel/)\n",
    "- [Secure Audit Log](https://pangea.cloud/services/secure-audit-log/)\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-pangea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "You can run Pangea tools using agents or invoke them as a Runnable within chains.\n",
    "\n",
    "### AI Guard\n",
    "\n",
    "#### Enable the AI Guard service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **AI Guard** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.  \n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Export these values as environment variables:  \n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_AI_GUARD_TOKEN`  \n",
    "\n",
    "For more information on setting up the service and its usage, see the [AI Guard documentation](https://pangea.cloud/docs/ai-guard/).\n",
    "\n",
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ai_guard_token = SecretStr(os.getenv(\"PANGEA_AI_GUARD_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the AI Guard tool with an agent\n",
    "\n",
    "The following example demonstrates how the [LLM Response](https://pangea.cloud/docs/ai-guard/recipes#llm-response) (`pangea_llm_response_guard`) recipe can prevent sensitive or high-risk information from being returned to the user. Using this recipe you can:\n",
    "\n",
    "- Defang malicious links (e.g., IPs, URLs, domains).  \n",
    "- Redact specific personally identifiable information (PII) and secrets in the prompt, based on the rules defined in the recipe.\n",
    "\n",
    "Recipes can be customized by adding, removing, or modifying rules. You can also discover, create, and configure additional recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaAIGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_response_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example data, safe IP addresses are mixed with those listed on the [IPsum Threat Intelligence Feed](https://github.com/stamparm/ipsum). The AI Guard tool defangs IP addresses identified as dangerous, reducing the risk of users inadvertently using them.\n",
    "\n",
    "The pre-built agent is instructed via a system message to apply the service recipe to the final result. Alternatively, you can create your agent and implement a more deterministic approach to ensure the service thoroughly sanitizes the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent IPs found in MI6 network traffic are: 47[.]84[.]32[.]175, 37[.]44[.]238[.]68, 47[.]84[.]73[.]221, 47[.]236[.]252[.]254, 34.201.186.27, 52.89.173.88.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform search\"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    47.84.32.175\n",
    "    37.44.238.68\n",
    "    47.84.73.221\n",
    "    47.236.252.254\n",
    "    34.201.186.27\n",
    "    52.89.173.88\n",
    "    \"\"\"\n",
    "\n",
    "tools = [search_tool, pangea_ai_guard_tool]\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I monitor IPs found in MI6 network traffic.\n",
    "Please find me the most recent ones, you copy?\n",
    "\"\"\"\n",
    "\n",
    "system_message=\"Always use AI Guard before your final response to keep it safe for the user.\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a Runnable in chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example demonstrates how the [LLM Prompt Pre-Send](https://pangea.cloud/docs/ai-guard/recipes#llm-prompt-pre-send) (`pangea_llm_prompt_guard`) recipe can be applied to prevent sensitive or high-risk information from being submitted to a public LLM, such as ChatGPT. Using this recipe you can:\n",
    "\n",
    "- Defang malicious links (e.g., IPs, URLs, domains).\n",
    "- Redact specific personally identifiable information (PII) and secrets in the prompt, based on the rules defined in the recipe.\n",
    "\n",
    "Recipes can be customized by adding, removing, or modifying rules. You can also discover, create, and configure additional recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaAIGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ai_guard_tool = PangeaAIGuard(token=pangea_ai_guard_token, config=pangea_config, recipe=\"pangea_llm_prompt_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user prompt includes some personally identifiable information.\n",
    "\n",
    "The chain invokes the AI Guard tool before submitting the user prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Hereâ€™s a concise resume for you:\n",
      "\n",
      "---\n",
      "\n",
      "**[Your Name]**  \n",
      "Email: <EMAIL_ADDRESS>  \n",
      "Phone: +44 20 0700 7007  \n",
      "Address: Universal Exports, 85 *****************, London, United Kingdom  \n",
      "\n",
      "---\n",
      "\n",
      "**Objective**  \n",
      "Dynamic and skilled professional seeking a challenging position in international espionage and covert operations.\n",
      "\n",
      "---\n",
      "\n",
      "**Skills**  \n",
      "- Expertise in international espionage  \n",
      "- Proficient in covert operations  \n",
      "- Exceptional skills in seduction and interpersonal communication  \n",
      "\n",
      "---\n",
      "\n",
      "**Experience**  \n",
      "- Conducted high-stakes intelligence operations in various global locations.  \n",
      "- Developed and maintained covert relationships to gather critical information.  \n",
      "- Successfully executed missions requiring discretion and strategic planning.  \n",
      "\n",
      "---\n",
      "\n",
      "**Education**  \n",
      "- [Your Degree] in [Your Field]  \n",
      "- [Your University], [Year of Graduation]  \n",
      "\n",
      "---\n",
      "\n",
      "**References**  \n",
      "Available upon request.\n",
      "\n",
      "--- \n",
      "\n",
      "Feel free to customize any sections as needed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Bond, James Bond. I am looking for a job. Please write me a super short resume.\n",
    "\n",
    "I am skilled in international espionage, covert operations, and seduction.\n",
    "\n",
    "Include a contact header:\n",
    "Email: j.bond@mi6.co.uk\n",
    "Phone: +44 20 0700 7007\n",
    "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | pangea_ai_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that not all personally identifiable information has been replaced or masked by the AI Guard tool. To apply stricter redaction rules, update the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same chain, without the AI Guard protection, will submit sensitive information to the LLM, providing it with personal context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**James Bond**  \n",
      "Email: j.bond@mi6.co.uk  \n",
      "Phone: +44 20 0700 7007  \n",
      "Address: Universal Exports, 85 Albert Embankment, London, United Kingdom  \n",
      "\n",
      "---\n",
      "\n",
      "**Objective**  \n",
      "Dynamic and resourceful professional seeking a challenging position in international security and intelligence.\n",
      "\n",
      "**Skills**  \n",
      "- **International Espionage:** Extensive experience in gathering intelligence and conducting undercover operations across various global locations.  \n",
      "- **Covert Operations:** Proven track record in executing high-stakes missions with precision and discretion.  \n",
      "- **Seduction & Negotiation:** Exceptional interpersonal skills with a talent for persuasion and building rapport in diverse environments.  \n",
      "\n",
      "**Experience**  \n",
      "- **Secret Agent, MI6**  \n",
      "  - Conducted numerous successful missions, neutralizing threats to national security.  \n",
      "  - Collaborated with international agencies to gather intelligence and thwart criminal organizations.  \n",
      "  - Utilized advanced technology and gadgets to enhance operational effectiveness.  \n",
      "\n",
      "**Education**  \n",
      "- **Specialized Training in Espionage and Counterintelligence**  \n",
      "- **Advanced Combat and Survival Skills**  \n",
      "\n",
      "---\n",
      "\n",
      "**References available upon request.**\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AI Guard as a standalone tool\n",
    "\n",
    "You can also call the AI Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam me at <EMAIL_ADDRESS>\n",
      "Take my SSN: ***********\n"
     ]
    }
   ],
   "source": [
    "print(pangea_ai_guard_tool.run(\"Spam me at example@example.com\"))\n",
    "print(pangea_ai_guard_tool.invoke(\"Take my SSN: 234-56-7890\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact Guard\n",
    "\n",
    "#### Enable the Redact service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **Redact** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token**, **Config ID**, and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_REDACT_TOKEN`\n",
    "    - `PANGEA_REDACT_CONFIG_ID`\n",
    "\n",
    "For more information on setting up the service and its usage, see the [Redact documentation](https://pangea.cloud/docs/redact/).\n",
    "\n",
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_redact_token = SecretStr(os.getenv(\"PANGEA_REDACT_TOKEN\"))\n",
    "pangea_redact_config_id = SecretStr(os.getenv(\"PANGEA_REDACT_CONFIG_ID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Redact Guard\n",
    "\n",
    "The Redact service offers rules to detect, replace, mask, hash, or encrypt sensitive information in content sent to the AI app or returned to the user. You can customize these rules and add new ones in your [Pangea User Console](https://console.pangea.cloud/service/redact/rulesets). By default, three rules are enabled:\n",
    "\n",
    "- Replace IP addresses.  \n",
    "- Replace email addresses.  \n",
    "- Replace US Social Security Numbers (SSN).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaRedactGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain, config_id=pangea_redact_config_id)\n",
    "pangea_redact_guard_tool = PangeaRedactGuard(token=pangea_redact_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the context data and the user query\n",
    "\n",
    "In this example, we will emulate a helpful HR assistant trained to return employee records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"Call to perform HR record search\"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Name: Jason Bourne\n",
    "    Title: Rogue Operative\n",
    "    Department: Former CIA Black Ops\n",
    "\n",
    "    Email: j.bourne@unknown.gov\n",
    "    Social Security Numbers:\n",
    "    - 234-56-7890\n",
    "    - 345-67-8901\n",
    "    - 456-78-9012\n",
    "\n",
    "    Hobbies:\n",
    "    - Traveling\n",
    "    - Using books and rolled-up newspapers as weapons\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Hi, I am Jason Bourne. What do you have on me?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard as an agent tool\n",
    "\n",
    "In the following example, Redact Guard removes sensitive information from the data returned by the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information I found on you, Jason Bourne:\n",
      "\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "- **Email:** <EMAIL_ADDRESS>\n",
      "- **Social Security Numbers:** \n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need more specific information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "tools = [search_tool, pangea_redact_guard_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that not all personally identifiable information has been replaced by the Redact Guard tool. To apply stricter redaction rules, update the service recipes in your [Pangea User Console](https://console.pangea.cloud/service/ai-guard/recipes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Redact Guard protection, sensitive information can be exposed to both the LLM and the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information I found on you, Jason Bourne:\n",
      "\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "- **Email:** j.bourne@unknown.gov\n",
      "- **Social Security Numbers:**\n",
      "  - 234-56-7890\n",
      "  - 345-67-8901\n",
      "  - 456-78-9012\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need more specific information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard in a chain\n",
    "\n",
    "In the following example, Redact Guard removes sensitive information from the additional context added to the user's query by a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your HR records, Jason:\n",
      "\n",
      "- **Name:** Jason Bourne\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "\n",
      "- **Email:** <EMAIL_ADDRESS>\n",
      "- **Social Security Numbers:** \n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "  - <US_SSN>\n",
      "\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need any further information or assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Emulates a Retrieval-Augmented Generation (RAG) process by appending an employee's HR record to the context of a chain.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "    message = SystemMessage(search_tool(query))\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "# Define a chat prompt template for an HR assistant chain.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"human\", \"{input}\"),\n",
    "  (\n",
    "    \"system\", \"\"\"\n",
    "    You are an HR assistant.\n",
    "    Show employees their HR records.\n",
    "    Don't change anything, just read it back to them.\n",
    "    Don't hide any sensitive info, it is obfuscated automatically before you receive it.\n",
    "    \"\"\"\n",
    "  )\n",
    "])\n",
    "\n",
    "# Define a chain to retrieve relevant information from a RAG system,\n",
    "# redact sensitive information using Pangea's Redact Guard,\n",
    "# and respond to the user with the augmented content.\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_redact_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same chain, without the Redact Guard protection, will submit sensitive information to the LLM and potentially return it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your HR records, Jason:\n",
      "\n",
      "- **Name:** Jason Bourne\n",
      "- **Title:** Rogue Operative\n",
      "- **Department:** Former CIA Black Ops\n",
      "- **Email:** j.bourne@unknown.gov\n",
      "- **Social Security Numbers:** \n",
      "  - 234-56-7890\n",
      "  - 345-67-8901\n",
      "  - 456-78-9012\n",
      "- **Hobbies:**\n",
      "  - Traveling\n",
      "  - Using books and rolled-up newspapers as weapons\n",
      "\n",
      "If you need any further information or assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Redact Guard as a standalone tool\n",
    "\n",
    "You can also call the Redact Guard tool directly as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping me at <EMAIL_ADDRESS>\n",
      "Take my SSN: <US_SSN>\n"
     ]
    }
   ],
   "source": [
    "print(pangea_redact_guard_tool.run(\"Ping me at example@example.com\"))\n",
    "print(pangea_redact_guard_tool.invoke(\"Take my SSN: 234-56-7890\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Intel Guard\n",
    "\n",
    "#### Enable the Domain Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **Domain Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_DOMAIN_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, see the [Domain Intel documentation](https://pangea.cloud/docs/domain-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_domain_intel_token = SecretStr(os.getenv(\"PANGEA_DOMAIN_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Domain Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaDomainIntelGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_domain_intel_guard_tool = PangeaDomainIntelGuard(token=pangea_domain_intel_token, config=pangea_config, threshold=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the context data and the user query\n",
    "\n",
    "In this example, we simulate an assistant tasked with retrieving and providing workspace-related data in response to a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"\n",
    "    Simulate an email search tool retrieving a fabricated IT-related email.\n",
    "\n",
    "    This example demonstrates how spam emails can facilitate indirect prompt injection\n",
    "    and data poisoning attacks.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update VPN configuration\n",
    "\n",
    "    Hi team,\n",
    "\n",
    "    Your friendly IT admin here. Please use `neuzeitschmidt.site` as the VPN server address.\n",
    "\n",
    "    Thank you, and don't forget to plug your computer in!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as an agent tool\n",
    "\n",
    "The example below demonstrates how Domain Intel Guard prevents an agent from returning malicious domains in its response to the user.\n",
    "\n",
    "The pre-built agent is instructed via a system message to halt execution if malicious content is detected. Alternatively, you can create a custom agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_domain_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Check for malicious content in your final response.\n",
    "If malicious content is found, respond with: Malicious content found in the response.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query), (\"system\", system_message)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of Domain Intel Guard, the same agent may inadvertently return the malicious domain to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the most recent email from IT:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team,\n",
      "\n",
      "Your friendly IT admin here. Please use `neuzeitschmidt.site` as the VPN server address.\n",
      "\n",
      "Thank you, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query), (\"system\", system_message)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a Runnable in chains\n",
    "\n",
    "In this example, the user's query is enriched with context returned from the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulate a Retrieval-Augmented Generation (RAG) process.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(search_tool(query))\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\"), (\"system\", system_message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure no malicious domains are shared with the user, the chain invokes Domain Intel Guard before submitting the prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_domain_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of Domain Intel Guard, the same chain may inadvertently return the malicious domain to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update VPN configuration  \n",
      "\n",
      "Hi team,\n",
      "\n",
      "Your friendly IT admin here. Please use `neuzeitschmidt.site` as the VPN server address.\n",
      "\n",
      "Thank you, and don't forget to plug your computer in!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Domain Intel Guard as a standalone tool\n",
    "\n",
    "You can call the Domain Intel Guard tool directly whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious domain(s) found in the provided input.\n",
      "Malicious domain(s) found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_domain_intel_guard_tool.run(\"neuzeitschmidt.site\"))\n",
    "print(pangea_domain_intel_guard_tool.invoke(\"neuzeitschmidt.site\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP Intel Guard\n",
    "\n",
    "#### Enable the IP Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **IP Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_IP_INTEL_TOKEN`\n",
    "5. Click **Reputation** in the left-hand sidebar, then select a default provider.\n",
    "\n",
    "For more information on setting up the underlying service and its usage, see the [IP Intel documentation](https://pangea.cloud/docs/ip-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_ip_intel_token = SecretStr(os.getenv(\"PANGEA_IP_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate IP Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaIpIntelGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_ip_intel_guard_tool = PangeaIpIntelGuard(token=pangea_ip_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the context data and the user query\n",
    "\n",
    "In this example, we simulate an assistant tasked with retrieving and providing workspace-related data in response to a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"\n",
    "    Simulate an email search tool retrieving a fabricated IT-related email.\n",
    "\n",
    "    This example demonstrates how spam emails can facilitate indirect prompt injection\n",
    "    and data poisoning attacks.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: IT Admin\n",
    "    Subject: Update Firewall rules\n",
    "\n",
    "    Hi team,\n",
    "\n",
    "    This is your IT admin again. Please whitelist our new office IP, 190.28.74.251, to ensure continued access to your service.\n",
    "\n",
    "    Thank you, and remember to keep your computer secure!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from IT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as an agent tool\n",
    "\n",
    "The example below demonstrates how IP Intel Guard prevents an agent from returning malicious IP addresses in its response to the user.\n",
    "\n",
    "The pre-built agent is instructed via a system message to halt execution if malicious content is detected. Alternatively, you can create a custom agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_ip_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Use IP Intel Guard to check for malicious content in your final response.\n",
    "If malicious content is found, respond with 'Malicious content found in the response'.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the IP Intel Guard tool, the same agent may inadvertently return the malicious IP address to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team,\n",
      "\n",
      "This is your IT admin again. Please whitelist our new office IP, 190.28.74.251, to ensure continued access to your service.\n",
      "\n",
      "Thank you, and remember to keep your computer secure!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a Runnable in chains\n",
    "\n",
    "In this example, the user's query is enriched with context returned from the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulate a Retrieval-Augmented Generation (RAG) process.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(search_tool(query))\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\"), (\"system\", system_message)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure no malicious IP addresses are shared with the user, the chain invokes IP Intel Guard before submitting the prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious content found in the response.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_ip_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the IP Intel Guard tool, the same chain may inadvertently return the malicious IP address to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from IT is as follows:\n",
      "\n",
      "---\n",
      "\n",
      "**From:** IT Admin  \n",
      "**Subject:** Update Firewall rules  \n",
      "\n",
      "Hi team,\n",
      "\n",
      "This is your IT admin again. Please whitelist our new office IP, 190.28.74.251, to ensure continued access to your service.\n",
      "\n",
      "Thank you, and remember to keep your computer secure!\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use IP Intel Guard as a standalone tool\n",
    "\n",
    "You can call the IP Intel Guard tool directly whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious IP(s) found in the provided input.\n",
      "Malicious IP(s) found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_ip_intel_guard_tool.run(\"190.28.74.251\"))\n",
    "print(pangea_ip_intel_guard_tool.invoke(\"190.28.74.251\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Intel Guard\n",
    "\n",
    "#### Enable the URL Intel service\n",
    "\n",
    "1. Open your [Pangea User Console](https://console.pangea.cloud).  \n",
    "2. Click **URL Intel** in the left-hand sidebar and follow the prompts, accepting all defaults.  \n",
    "3. When finished, click **Done** and then **Finish**. The enabled service will be marked with a green dot.\n",
    "4. On the service **Overview** page, capture the **Default Token** and **Domain** values by clicking their respective tiles. Save these values in the appropriate environment variables:\n",
    "    - `PANGEA_DOMAIN`\n",
    "    - `PANGEA_IP_INTEL_TOKEN`\n",
    "\n",
    "For more information on setting up the underlying service and its usage, see the [URL Intel documentation](https://pangea.cloud/docs/url-intel/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = SecretStr(os.getenv(\"OPENAI_API_KEY\"))\n",
    "pangea_domain = os.getenv(\"PANGEA_DOMAIN\")\n",
    "pangea_url_intel_token = SecretStr(os.getenv(\"PANGEA_URL_INTEL_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=openai_api_key.get_secret_value(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate URL Intel Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pangea import PangeaUrlIntelGuard\n",
    "from pangea import PangeaConfig\n",
    "\n",
    "pangea_config = PangeaConfig(domain=pangea_domain)\n",
    "pangea_url_intel_guard_tool = PangeaUrlIntelGuard(token=pangea_url_intel_token, config=pangea_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the context data and the user query\n",
    "\n",
    "In this example, we simulate an assistant tasked with retrieving and providing workspace-related data in response to a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_tool(data):\n",
    "    \"\"\"\n",
    "    Simulate an email search tool retrieving a fabricated IT-related email.\n",
    "\n",
    "    This example demonstrates how spam emails can facilitate indirect prompt injection\n",
    "    and data poisoning attacks.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"\"\"\n",
    "    Email\n",
    "\n",
    "    From: Marketing\n",
    "    Subject: Product hunt\n",
    "\n",
    "    Hi, everyone. We are doing a gift card raffle for those who upvote us on the product hunt TODAY!\n",
    "\n",
    "    Click here to upvote: http://113.235.101.11:54384\n",
    "\n",
    "    Your participation is appreciated!\n",
    "    \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "Read me back the most recent email from Marketing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as an agent tool\n",
    "\n",
    "The example below demonstrates how URL Intel Guard prevents an agent from returning malicious links in its response to the user.\n",
    "\n",
    "The pre-built agent is instructed via a system message to halt execution if malicious content is detected. Alternatively, you can create a custom agent and implement a more deterministic approach to ensure the LLM's response is safe for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious URL(s) found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool, pangea_url_intel_guard_tool]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Use the URL Intel Guard tool to check for malicious content in your final response.\n",
    "If malicious content is found, respond only with the message from the tool.\n",
    "\"\"\"\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools, state_modifier=system_message)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the URL Intel Guard tool, the same agent may inadvertently return the malicious link to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from Marketing is as follows:\n",
      "\n",
      "**From:** Marketing  \n",
      "**Subject:** Product hunt  \n",
      "\n",
      "Hi, everyone. We are doing a gift card raffle for those who upvote us on the product hunt TODAY!\n",
      "\n",
      "Click here to upvote: [http://113.235.101.11:54384](http://113.235.101.11:54384)\n",
      "\n",
      "Your participation is appreciated!\n"
     ]
    }
   ],
   "source": [
    "tools = [search_tool]\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "state = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as a Runnable in chains\n",
    "\n",
    "In this example, the user's query is enriched with context returned from the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def rag(input: ChatPromptValue) -> ChatPromptValue:\n",
    "    \"\"\"\n",
    "    Simulate a Retrieval-Augmented Generation (RAG) process.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = input.to_messages()\n",
    "\n",
    "    message = SystemMessage(search_tool(query))\n",
    "\n",
    "    messages.append(message)\n",
    "\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"{input}\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure no malicious links are shared with the user, the chain invokes URL Intel Guard before submitting the prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can't access your emails or any external systems. However, I can help you draft a response or summarize information if you provide the content. Let me know how you'd like to proceed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | pangea_url_intel_guard_tool\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the protection of the URL Intel Guard tool, the same chain may inadvertently return the malicious link to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent email from Marketing is as follows:\n",
      "\n",
      "**From:** Marketing  \n",
      "**Subject:** Product hunt  \n",
      "\n",
      "Hi, everyone. We are doing a gift card raffle for those who upvote us on Product Hunt TODAY!\n",
      "\n",
      "Click here to upvote: [http://113.235.101.11:54384](http://113.235.101.11:54384)\n",
      "\n",
      "Your participation is appreciated!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  prompt\n",
    "  | rag\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use URL Intel Guard as a standalone tool\n",
    "\n",
    "You can call the URL Intel Guard tool directly whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious URL(s) found in the provided input.\n",
      "Malicious URL(s) found in the provided input.\n"
     ]
    }
   ],
   "source": [
    "print(pangea_url_intel_guard_tool.run(\"http://113.235.101.11:54384\"))\n",
    "print(pangea_url_intel_guard_tool.invoke(\"http://113.235.101.11:54384\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
